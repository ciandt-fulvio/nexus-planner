"""
SQLAlchemy ORM table definitions for Nexus API.

Defines the database schema for all entities:
- CommitTable: Git commits with file changes
- RepositoryTable: Git repositories with metadata
- PersonTable: Developers identified by email
- AlertTable: AI-generated alerts cached by entity
- FeatureAnalysisTable: Feature impact analyses

Docs: https://docs.sqlalchemy.org/en/20/orm/mapping_styles.html
Docs: https://docs.sqlalchemy.org/en/20/core/type_basics.html

Sample input: Database session
Expected output: ORM model instances for CRUD operations
"""

from datetime import datetime

from sqlalchemy import DateTime, ForeignKey, Integer, String, Text
from sqlalchemy.dialects.sqlite import JSON
from sqlalchemy.orm import Mapped, mapped_column

from nexus_api.db.database import Base


class CommitTable(Base):
    """
    Git commit record.

    Primary unit of storage representing a synchronized Git commit.
    Used for calculating metrics like activity, concentration, and hotspots.
    """

    __tablename__ = "commits"

    # Primary key: SHA-1 hash (40 chars)
    id: Mapped[str] = mapped_column(String(40), primary_key=True)

    # Foreign key to repository
    repository_id: Mapped[str] = mapped_column(
        String(36), ForeignKey("repositories.id"), index=True
    )

    # Author information
    author_name: Mapped[str] = mapped_column(String(255))
    author_email: Mapped[str] = mapped_column(String(255), index=True)

    # Committer information (may differ from author)
    committer_name: Mapped[str] = mapped_column(String(255))
    committer_email: Mapped[str] = mapped_column(String(255))

    # Timestamps (timezone-aware UTC)
    author_date: Mapped[datetime] = mapped_column(DateTime(timezone=True))
    commit_date: Mapped[datetime] = mapped_column(DateTime(timezone=True), index=True)

    # Commit content
    message: Mapped[str] = mapped_column(Text)

    # Files changed: [{"path": "...", "status": "added|modified|deleted"}]
    files_changed: Mapped[list] = mapped_column(JSON, default=list)

    # Line statistics
    additions: Mapped[int] = mapped_column(Integer, default=0)
    deletions: Mapped[int] = mapped_column(Integer, default=0)

    # Parent commits (for merge detection): ["sha1", "sha2"]
    parent_shas: Mapped[list | None] = mapped_column(JSON, nullable=True)


class RepositoryTable(Base):
    """
    Git repository metadata.

    Stores repository information and reference for alert cache invalidation.
    Calculated fields (activity, topContributors, etc.) are computed at runtime.
    """

    __tablename__ = "repositories"

    # Primary key: UUID
    id: Mapped[str] = mapped_column(String(36), primary_key=True)

    # Repository identification
    name: Mapped[str] = mapped_column(String(255), index=True)
    description: Mapped[str | None] = mapped_column(Text, nullable=True)
    git_url: Mapped[str] = mapped_column(String(500))

    # Alert cache invalidation reference
    last_alerts_pr_id: Mapped[str | None] = mapped_column(String(100), nullable=True)

    # Timestamps
    created_at: Mapped[datetime] = mapped_column(
        DateTime(timezone=True), default=datetime.utcnow
    )
    updated_at: Mapped[datetime] = mapped_column(
        DateTime(timezone=True), default=datetime.utcnow, onupdate=datetime.utcnow
    )


class PersonTable(Base):
    """
    Developer identified by email.

    Represents a person who has contributed commits.
    Calculated fields (technologies, expertise, etc.) are computed at runtime.
    """

    __tablename__ = "persons"

    # Primary key: UUID
    id: Mapped[str] = mapped_column(String(36), primary_key=True)

    # Unique identifier
    email: Mapped[str] = mapped_column(String(255), unique=True, index=True)

    # Display information
    name: Mapped[str] = mapped_column(String(255))
    avatar: Mapped[str | None] = mapped_column(String(10), nullable=True)

    # Alert cache invalidation reference
    last_alert_commit_sha: Mapped[str | None] = mapped_column(String(40), nullable=True)

    # Timestamps
    created_at: Mapped[datetime] = mapped_column(
        DateTime(timezone=True), default=datetime.utcnow
    )
    updated_at: Mapped[datetime] = mapped_column(
        DateTime(timezone=True), default=datetime.utcnow, onupdate=datetime.utcnow
    )


class AlertTable(Base):
    """
    AI-generated alert cache.

    Stores alerts generated by AI for repositories and persons.
    Invalidated when reference_id (PR ID or commit SHA) changes.
    """

    __tablename__ = "alerts"

    # Primary key: UUID
    id: Mapped[str] = mapped_column(String(36), primary_key=True)

    # Entity reference (polymorphic)
    entity_type: Mapped[str] = mapped_column(String(20))  # "repository" or "person"
    entity_id: Mapped[str] = mapped_column(String(36), index=True)

    # Cache invalidation reference (PR ID or commit SHA)
    reference_id: Mapped[str | None] = mapped_column(String(100), nullable=True, index=True)

    # Alert content
    title: Mapped[str] = mapped_column(String(100))
    description: Mapped[str] = mapped_column(Text)  # Markdown with dynamic links
    severity: Mapped[str] = mapped_column(String(10))  # "info", "warning", "critical"
    category: Mapped[str | None] = mapped_column(String(50), nullable=True)
    suggested_actions: Mapped[str | None] = mapped_column(Text, nullable=True)

    # Timestamp
    created_at: Mapped[datetime] = mapped_column(
        DateTime(timezone=True), default=datetime.utcnow
    )


class FeatureAnalysisTable(Base):
    """
    Feature impact analysis.

    Stores AI-generated analysis of feature impact in Markdown format.
    Contains dynamic links for interactive navigation.
    """

    __tablename__ = "feature_analyses"

    # Primary key: UUID
    id: Mapped[str] = mapped_column(String(36), primary_key=True)

    # Analysis content
    feature_description: Mapped[str] = mapped_column(Text)
    analysis_text: Mapped[str] = mapped_column(Text)  # Markdown with dynamic links

    # Timestamp
    created_at: Mapped[datetime] = mapped_column(
        DateTime(timezone=True), default=datetime.utcnow, index=True
    )


if __name__ == "__main__":
    import sys
    from sqlalchemy import inspect

    all_failures: list[str] = []
    total_tests = 0

    # Test 1: CommitTable exists and has correct name
    total_tests += 1
    if CommitTable.__tablename__ != "commits":
        all_failures.append(
            f"CommitTable name: Expected 'commits', got '{CommitTable.__tablename__}'"
        )

    # Test 2: CommitTable has all required columns
    total_tests += 1
    mapper = inspect(CommitTable)
    commit_columns = [c.key for c in mapper.columns]
    required_commit_cols = [
        "id", "repository_id", "author_name", "author_email",
        "committer_name", "committer_email", "author_date", "commit_date",
        "message", "files_changed", "additions", "deletions", "parent_shas"
    ]
    for col in required_commit_cols:
        if col not in commit_columns:
            all_failures.append(f"CommitTable missing column: {col}")

    # Test 3: RepositoryTable exists and has correct name
    total_tests += 1
    if RepositoryTable.__tablename__ != "repositories":
        all_failures.append(
            f"RepositoryTable name: Expected 'repositories', got '{RepositoryTable.__tablename__}'"
        )

    # Test 4: RepositoryTable has all required columns
    total_tests += 1
    mapper = inspect(RepositoryTable)
    repo_columns = [c.key for c in mapper.columns]
    required_repo_cols = [
        "id", "name", "description", "git_url",
        "last_alerts_pr_id", "created_at", "updated_at"
    ]
    for col in required_repo_cols:
        if col not in repo_columns:
            all_failures.append(f"RepositoryTable missing column: {col}")

    # Test 5: PersonTable exists and has correct name
    total_tests += 1
    if PersonTable.__tablename__ != "persons":
        all_failures.append(
            f"PersonTable name: Expected 'persons', got '{PersonTable.__tablename__}'"
        )

    # Test 6: PersonTable has all required columns
    total_tests += 1
    mapper = inspect(PersonTable)
    person_columns = [c.key for c in mapper.columns]
    required_person_cols = [
        "id", "email", "name", "avatar",
        "last_alert_commit_sha", "created_at", "updated_at"
    ]
    for col in required_person_cols:
        if col not in person_columns:
            all_failures.append(f"PersonTable missing column: {col}")

    # Test 7: AlertTable exists and has correct name
    total_tests += 1
    if AlertTable.__tablename__ != "alerts":
        all_failures.append(
            f"AlertTable name: Expected 'alerts', got '{AlertTable.__tablename__}'"
        )

    # Test 8: AlertTable has all required columns
    total_tests += 1
    mapper = inspect(AlertTable)
    alert_columns = [c.key for c in mapper.columns]
    required_alert_cols = [
        "id", "entity_type", "entity_id", "reference_id",
        "title", "description", "severity", "category",
        "suggested_actions", "created_at"
    ]
    for col in required_alert_cols:
        if col not in alert_columns:
            all_failures.append(f"AlertTable missing column: {col}")

    # Test 9: FeatureAnalysisTable exists and has correct name
    total_tests += 1
    if FeatureAnalysisTable.__tablename__ != "feature_analyses":
        all_failures.append(
            f"FeatureAnalysisTable name: Expected 'feature_analyses', got '{FeatureAnalysisTable.__tablename__}'"
        )

    # Test 10: FeatureAnalysisTable has all required columns
    total_tests += 1
    mapper = inspect(FeatureAnalysisTable)
    fa_columns = [c.key for c in mapper.columns]
    required_fa_cols = ["id", "feature_description", "analysis_text", "created_at"]
    for col in required_fa_cols:
        if col not in fa_columns:
            all_failures.append(f"FeatureAnalysisTable missing column: {col}")

    # Final validation result
    if all_failures:
        print(f"❌ VALIDATION FAILED - {len(all_failures)} of {total_tests} tests failed:")
        for failure in all_failures:
            print(f"  - {failure}")
        sys.exit(1)
    else:
        print(f"✅ VALIDATION PASSED - All {total_tests} tests produced expected results")
        sys.exit(0)
